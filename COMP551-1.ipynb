{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN8tsPD8Fw+CKHgJFkBRPjw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Environment Setup and Project Initialization\n","\n","This section prepares the Google Colab environment for the project by connecting it to Google Drive and navigating to the project directory where all code and data files are stored. Mounting Google Drive ensures that files persist across Colab sessions, while changing the working directory allows the notebook to access local project files such as scripts and datasets. The directory check at the end serves as a simple sanity check to confirm that the correct project folder and expected files are available before proceeding."],"metadata":{"id":"2kDPoauXbNUn"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"HfBZjl8AOAWs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769810744826,"user_tz":300,"elapsed":33596,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"outputId":"1c2fd2e6-32ad-421d-f2fa-affe96ea3970"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/comp551-Ass1\n","Current directory: /content/drive/MyDrive/comp551-Ass1\n","Files here: ['.git', 'data_parser.py', '__pycache__', 'data', 'linear_regression.py', 'COMP551-1.ipynb']\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","PROJECT_PATH = \"/content/drive/MyDrive/comp551-Ass1\"\n","%cd $PROJECT_PATH\n","\n","import os\n","print(\"Current directory:\", os.getcwd())\n","print(\"Files here:\", os.listdir())"]},{"cell_type":"markdown","source":["Importing the Data Processing Utilities\n","\n","In this step, we import the preprocessing function responsible for loading and preparing the Bike Sharing dataset, as well as NumPy for numerical operations. The process_csv function handles data cleaning, encoding of categorical variables, feature scaling, and the train–test split, allowing the rest of the notebook to work directly with clean, machine-learning-ready NumPy arrays."],"metadata":{"id":"Qhre0qCBbl9_"}},{"cell_type":"code","source":["from data_parser import process_csv\n","import numpy as np"],"metadata":{"id":"ks8q7QYm5EqL","executionInfo":{"status":"ok","timestamp":1769810747637,"user_tz":300,"elapsed":2791,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Loading and Preprocessing the Dataset\n","\n","Here, we load the Bike Sharing dataset and apply all preprocessing steps in one call. This function reads the raw CSV file, validates the data, encodes categorical variables, standardizes continuous features, and performs a time-aware train–test split. The result is four NumPy arrays: training inputs, testing inputs, and their corresponding target values, which are ready to be used directly for model training and evaluation."],"metadata":{"id":"nNZkJc19brlG"}},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = process_csv(\"data/day.csv\")"],"metadata":{"id":"Zcl8WYYKj8Ck","executionInfo":{"status":"ok","timestamp":1769810748243,"user_tz":300,"elapsed":603,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Ensuring Numeric Data Types\n","\n","Here, we convert all input and target arrays to float64 to guarantee compatibility with NumPy’s linear algebra operations and avoid issues caused by mixed data types during model training."],"metadata":{"id":"JKpHKQMxb-Rk"}},{"cell_type":"code","source":["X_train = X_train.astype(np.float64)\n","X_test = X_test.astype(np.float64)\n","y_train = y_train.astype(np.float64)\n","y_test = y_test.astype(np.float64)"],"metadata":{"id":"SWHMJPKDhwi8","executionInfo":{"status":"ok","timestamp":1769810748252,"user_tz":300,"elapsed":4,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["print(\"X_train dtype:\", X_train.dtype)\n","print(\"y_train dtype:\", y_train.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-aMiPqo4kqQn","executionInfo":{"status":"ok","timestamp":1769810748284,"user_tz":300,"elapsed":17,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"outputId":"5e36e53b-6291-41f1-d448-27d7ddee3b14"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train dtype: float64\n","y_train dtype: float64\n"]}]},{"cell_type":"markdown","source":["#Inspecting Dataset Dimensions\n","\n","This cell prints the shapes of the training and testing inputs and targets to verify that the data has been split correctly and that each input matrix aligns with its corresponding label vector."],"metadata":{"id":"DBxI1_tncZxw"}},{"cell_type":"code","source":["print(\"X_train shape:\", X_train.shape)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"y_test shape:\", y_test.shape)"],"metadata":{"id":"BlsoORqa91jc","executionInfo":{"status":"ok","timestamp":1769810748297,"user_tz":300,"elapsed":10,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"358fff20-a44a-44b8-b773-e81037ca10ae"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape: (584, 29)\n","X_test shape: (147, 29)\n","y_train shape: (584,)\n","y_test shape: (147,)\n"]}]},{"cell_type":"markdown","source":["Previewing Sample Data\n","\n","This step displays a few rows from the training data and their corresponding target values as a quick sanity check. It helps confirm that the features and labels look reasonable before training the model."],"metadata":{"id":"AegNLQ4HcrxJ"}},{"cell_type":"code","source":["print(X_train[:3])\n","print(y_train[:3])"],"metadata":{"id":"saZvfwTGA2Y-","executionInfo":{"status":"ok","timestamp":1769810748311,"user_tz":300,"elapsed":12,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"60f92f53-5328-467b-ca11-b7c199569834"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 1.          0.          0.         -0.81385634  1.23613525 -0.44488315\n","   0.          0.          0.          0.          0.          0.\n","   0.          0.          0.          0.          0.          0.\n","   0.          0.          0.          0.          0.          0.\n","   0.          1.          1.          0.          0.        ]\n"," [ 1.          0.          0.         -0.71121466  0.49355952  0.71244778\n","   0.          0.          0.          0.          0.          0.\n","   0.          0.          0.          0.          0.          0.\n","   0.          0.          0.          0.          0.          0.\n","   0.          0.          1.          0.          0.        ]\n"," [ 1.          0.          0.         -1.59945776 -1.25765687  0.70942613\n","   0.          0.          0.          0.          0.          0.\n","   0.          0.          0.          0.          0.          0.\n","   0.          0.          1.          0.          0.          0.\n","   0.          0.          0.          0.          0.        ]]\n","[ 985.  801. 1349.]\n"]}]},{"cell_type":"markdown","source":["#Implementing Linear Regression from Scratch\n","\n","This part creates the linear_regression.py and defines a simple linear regression model using NumPy. The fit method learns the weight vector using a stable closed-form solution, while the predict method uses those learned weights to generate predictions through matrix multiplication."],"metadata":{"id":"XWfsLi5gc8Jp"}},{"cell_type":"code","source":["%%writefile linear_regression.py\n","import numpy as np\n","\n","class LinearRegression:\n","    def __init__(self):\n","        self.w = None\n","\n","    def fit(self, X, y):\n","        self.w = np.linalg.lstsq(X, y, rcond=None)[0]\n","\n","    def predict(self, X):\n","        return X @ self.w"],"metadata":{"id":"x5Ai5IGVJnAD","executionInfo":{"status":"ok","timestamp":1769810749177,"user_tz":300,"elapsed":859,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"aef62d3e-9199-47b5-a9e4-4a5201b187be"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting linear_regression.py\n"]}]},{"cell_type":"markdown","source":["#Training the Linear Regression Model\n","\n","Here, we initialize the linear regression model and fit it to the training data. This process learns the optimal weight vector that best maps the input features to the target bike rental counts."],"metadata":{"id":"juapcn53eZDm"}},{"cell_type":"code","source":["from linear_regression import LinearRegression\n","\n","model = LinearRegression()\n","model.fit(X_train, y_train)"],"metadata":{"id":"lZS6LpzJcK59","executionInfo":{"status":"ok","timestamp":1769811294798,"user_tz":300,"elapsed":10,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"SGk2_wg0eXdz"}},{"cell_type":"code","source":["print(\"Weight vector shape:\", model.w.shape)"],"metadata":{"id":"UfcyMev9hmrc","executionInfo":{"status":"ok","timestamp":1769810749914,"user_tz":300,"elapsed":16,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5e461ee9-9b4d-4bd6-9b6e-aa9101c64e20"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Weight vector shape: (29,)\n"]}]},{"cell_type":"markdown","source":["Generating Model Predictions\n","\n","Here, we use the trained linear regression model to generate predictions for both the training and testing datasets. These predicted values will be used to evaluate how well the model fits the data and how it generalizes to unseen examples."],"metadata":{"id":"zpT8EKCGfz5a"}},{"cell_type":"code","source":["y_train_pred = model.predict(X_train)\n","y_test_pred = model.predict(X_test)"],"metadata":{"id":"YJWxzX81jZKC","executionInfo":{"status":"ok","timestamp":1769810749917,"user_tz":300,"elapsed":2,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["print(y_train_pred.shape)\n","print(y_test_pred.shape)"],"metadata":{"id":"JcVQnSVqmaen","executionInfo":{"status":"ok","timestamp":1769810749936,"user_tz":300,"elapsed":15,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"24da5e67-9044-4b17-b9a0-a09a61d0fc6e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["(584,)\n","(147,)\n"]}]},{"cell_type":"code","source":["print(\"True:\", y_train[:5])\n","print(\"Pred:\", y_train_pred[:5])"],"metadata":{"id":"RsupunUBmtVA","executionInfo":{"status":"ok","timestamp":1769810749982,"user_tz":300,"elapsed":43,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9930bbf8-05ec-4f18-8719-09709f1b1d67"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["True: [ 985.  801. 1349. 1562. 1600.]\n","Pred: [1303.61781844  993.39686106 1206.20983334 1385.36075853 1567.21709833]\n"]}]},{"cell_type":"markdown","source":["#Defining the Mean Squared Error Metric\n","\n","This cell defines a simple function to compute Mean Squared Error, which measures the average squared difference between the true target values and the model’s predictions."],"metadata":{"id":"pSTUnEUBf6yh"}},{"cell_type":"code","source":["def mse(y_true, y_pred):\n","    return np.mean((y_true - y_pred) ** 2)\n","\n"],"metadata":{"id":"BgPOk4T6dvhP","executionInfo":{"status":"ok","timestamp":1769810749983,"user_tz":300,"elapsed":11,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["Evaluating Baseline Model Performance\n","\n","This step computes and reports the Mean Squared Error on both the training and testing sets, providing a baseline measure of how well the linear regression model fits the data and generalizes to unseen observations."],"metadata":{"id":"GWoHiHmpggwV"}},{"cell_type":"code","source":["train_mse = mse(y_train, y_train_pred)\n","test_mse = mse(y_test, y_test_pred)\n","\n","print(\"Training MSE:\", train_mse)\n","print(\"Test MSE:\", test_mse)"],"metadata":{"id":"adxU7xPieWik","executionInfo":{"status":"ok","timestamp":1769810749985,"user_tz":300,"elapsed":11,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1ecfec75-fd2b-48bb-d1d3-568b725575c7"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Training MSE: 462669.79441381706\n","Test MSE: 1218080.5473418413\n"]}]},{"cell_type":"markdown","source":["Interpreting Error in Original Units\n","\n","Here, we compute the Root Mean Squared Error to express the model’s prediction error in the original unit of bike rentals, making the results easier to interpret in practical terms."],"metadata":{"id":"PD2AnZTxjeC0"}},{"cell_type":"code","source":["print(\"Training RMSE:\", np.sqrt(train_mse))\n","print(\"Test RMSE:\", np.sqrt(test_mse))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-DL2HV_SeaVl","executionInfo":{"status":"ok","timestamp":1769812700819,"user_tz":300,"elapsed":51,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"outputId":"182b39ae-1a3d-4a41-e15e-079a381b3551"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Training RMSE: 680.1983493171805\n","Test RMSE: 1103.6668642945847\n"]}]},{"cell_type":"markdown","source":["#Feature Engineering\n","Identifying Continuous Feature Indices\n","\n","This parts inspects the feature matrix to locate the indices of continuous variables used for feature engineering. We are examining feature magnitudes in a sample row to distinguish standardized continuous features from binary one-hot encoded columns, allowing us to target only the appropriate variables for nonlinear transformations."],"metadata":{"id":"Isyvr_JmIlTz"}},{"cell_type":"code","source":["print(\"Number of features:\", X_train.shape[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"phIYwlQoIjQy","executionInfo":{"status":"ok","timestamp":1769813983243,"user_tz":300,"elapsed":8,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"outputId":"7cc5b0b5-80c2-4d51-a576-6145f6343425"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of features: 29\n"]}]},{"cell_type":"code","source":["X_train[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TzYE0iFIIzCa","executionInfo":{"status":"ok","timestamp":1769814048901,"user_tz":300,"elapsed":42,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"outputId":"301f87fe-8655-4018-fa16-43770bd1fbf4"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 1.        ,  0.        ,  0.        , -0.81385634,  1.23613525,\n","       -0.44488315,  0.        ,  0.        ,  0.        ,  0.        ,\n","        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n","        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n","        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n","        1.        ,  1.        ,  0.        ,  0.        ])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["for i, v in enumerate(X_train[0]):\n","    if abs(v) > 0.2 and abs(v) < 2:\n","        print(i, v)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HpoJ556VL5Dk","executionInfo":{"status":"ok","timestamp":1769814860801,"user_tz":300,"elapsed":48,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"outputId":"278d6ad1-03a4-4672-ff39-27365e557de5"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["0 1.0\n","3 -0.8138563421371906\n","4 1.236135247071073\n","5 -0.4448831480680497\n","25 1.0\n","26 1.0\n"]}]},{"cell_type":"markdown","source":["In this step, we explicitly record the column indices corresponding to temperature, humidity, and wind speed. These indices are used to apply polynomial and interaction-based feature engineering only to the continuous variables."],"metadata":{"id":"_fXL3ciVkTvK"}},{"cell_type":"code","source":["temp_idx = 3\n","hum_idx = 4\n","wind_idx = 5"],"metadata":{"id":"sosn08jARU4K","executionInfo":{"status":"ok","timestamp":1769816283319,"user_tz":300,"elapsed":43,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["print(X_train[0, temp_idx],\n","      X_train[0, hum_idx],\n","      X_train[0, wind_idx])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CNwF0jK8MCBg","executionInfo":{"status":"ok","timestamp":1769816293423,"user_tz":300,"elapsed":12,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"outputId":"c8acbaa2-cdc2-4c24-9160-c5dcffe7529a"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["-0.8138563421371906 1.236135247071073 -0.4448831480680497\n"]}]},{"cell_type":"markdown","source":["Adding Nonlinear Feature Engineering\n","\n","This part defines a utility function that augments the original feature matrix with polynomial and interaction terms derived from temperature, humidity, and wind speed. These additional features allow the linear regression model to capture nonlinear effects and interactions between weather variables while keeping the model itself linear in its parameters."],"metadata":{"id":"83tR1Dndkp1w"}},{"cell_type":"code","source":["%%writefile feature_engineering.py\n","import numpy as np\n","\n","def add_nonlinear_features(X, temp_idx, hum_idx, wind_idx):\n","    \"\"\"\n","    Adds polynomial and interaction features for selected continuous columns.\n","\n","    Parameters:\n","    - X: NumPy array (already includes bias column)\n","    - temp_idx, hum_idx, wind_idx: indices of continuous features\n","\n","    Returns:\n","    - X_new: expanded feature matrix\n","    \"\"\"\n","\n","    # Extract continuous features\n","    temp = X[:, temp_idx]\n","    hum = X[:, hum_idx]\n","    wind = X[:, wind_idx]\n","\n","    # Polynomial features\n","    temp_sq = temp ** 2\n","    hum_sq = hum ** 2\n","    wind_sq = wind ** 2\n","\n","    # Interaction features\n","    temp_hum = temp * hum\n","    temp_wind = temp * wind\n","    hum_wind = hum * wind\n","\n","    # Concatenate original features with new ones\n","    X_new = np.column_stack([\n","        X,\n","        temp_sq,\n","        hum_sq,\n","        wind_sq,\n","        temp_hum,\n","        temp_wind,\n","        hum_wind\n","    ])\n","\n","    return X_new"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k4jIJc4jRihl","executionInfo":{"status":"ok","timestamp":1769816478126,"user_tz":300,"elapsed":45,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"outputId":"d93b8189-1c03-4fe7-96ac-e1e5035cb1a0"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing feature_engineering.py\n"]}]},{"cell_type":"markdown","source":["Applying Feature Engineering to the Dataset\n","\n","Here, we apply the nonlinear feature expansion to both the training and testing sets, ensuring consistency between them. Printing the shapes confirms that new features were added correctly while keeping the number of data points unchanged."],"metadata":{"id":"f_qF5eoNlOn3"}},{"cell_type":"code","source":["from feature_engineering import add_nonlinear_features"],"metadata":{"id":"-jp34XUHSKCs","executionInfo":{"status":"ok","timestamp":1769816500774,"user_tz":300,"elapsed":19,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["X_train_fe = add_nonlinear_features(X_train, temp_idx, hum_idx, wind_idx)\n","X_test_fe = add_nonlinear_features(X_test, temp_idx, hum_idx, wind_idx)"],"metadata":{"id":"dH4dpxBCSRyh","executionInfo":{"status":"ok","timestamp":1769816532258,"user_tz":300,"elapsed":40,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["print(\"Original X_train shape:\", X_train.shape)\n","print(\"Feature-engineered X_train shape:\", X_train_fe.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LO5DtWl8SXsF","executionInfo":{"status":"ok","timestamp":1769816557994,"user_tz":300,"elapsed":9,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"outputId":"9403cb19-1167-4a70-d630-9d25de1234e3"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Original X_train shape: (584, 29)\n","Feature-engineered X_train shape: (584, 35)\n"]}]},{"cell_type":"markdown","source":["Training and Evaluating the Feature-Engineered Model\n","\n","This step retrains the linear regression model using the feature-engineered inputs and evaluates its performance. By comparing the training and test MSE before and after feature engineering, we can see the impact of adding polynomial and interaction terms, confirming that the enhanced features lead to improved model fit."],"metadata":{"id":"B7jzVRXql4Dp"}},{"cell_type":"code","source":["from linear_regression import LinearRegression\n","\n","model_fe = LinearRegression()\n","model_fe.fit(X_train_fe, y_train)"],"metadata":{"id":"08QN6B61XjR2","executionInfo":{"status":"ok","timestamp":1769817915741,"user_tz":300,"elapsed":36,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["y_train_pred_fe = model_fe.predict(X_train_fe)\n","y_test_pred_fe = model_fe.predict(X_test_fe)"],"metadata":{"id":"cCyx4eAfXl83","executionInfo":{"status":"ok","timestamp":1769817927754,"user_tz":300,"elapsed":5,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["train_mse_fe = mse(y_train, y_train_pred_fe)\n","test_mse_fe = mse(y_test, y_test_pred_fe)\n","\n","print(\"Training MSE (before):\", train_mse)\n","print(\"Training MSE (after): \", train_mse_fe)\n","\n","print(\"Test MSE (before):\", test_mse)\n","print(\"Test MSE (after): \", test_mse_fe)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lyPFNobAXpgU","executionInfo":{"status":"ok","timestamp":1769817940984,"user_tz":300,"elapsed":20,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"outputId":"f0d9b8bb-0cee-44ba-ab8a-bd6e96acedff"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Training MSE (before): 462669.79441381706\n","Training MSE (after):  376557.30994621356\n","Test MSE (before): 1218080.5473418413\n","Test MSE (after):  1023757.6634041732\n"]}]},{"cell_type":"code","source":["!pwd\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZrZTgoVbmu0p","executionInfo":{"status":"ok","timestamp":1769821894540,"user_tz":300,"elapsed":209,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"outputId":"1072f31b-6683-4436-cb88-3c59c5d00fcc"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/comp551-Ass1\n","COMP551-1.ipynb  data_parser.py\t\t linear_regression.py\n","data\t\t feature_engineering.py  __pycache__\n"]}]},{"cell_type":"code","source":["!git config --global user.name \"Victor-Akinode\"\n","!git config --global user.email \"victorakinode@gmail.com\""],"metadata":{"id":"I9mpQw0wm0OY","executionInfo":{"status":"ok","timestamp":1769821993145,"user_tz":300,"elapsed":213,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["%%writefile .gitignore\n","# Google Drive metadata files\n","*.gsheet\n","*.gdoc\n","*.gslides\n","\n","# Colab / Jupyter\n",".ipynb_checkpoints/\n","\n","# Python cache\n","__pycache__/\n","*.pyc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MrnKzV6xnLEN","executionInfo":{"status":"ok","timestamp":1769822368800,"user_tz":300,"elapsed":102,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"outputId":"bad9cab7-9d73-4317-9179-ab99d7b93edf"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting .gitignore\n"]}]},{"cell_type":"code","source":["!git rm --cached data/day.gsheet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KMCVo8_PoiWG","executionInfo":{"status":"ok","timestamp":1769822373928,"user_tz":300,"elapsed":114,"user":{"displayName":"Victor Akinode","userId":"15309799102562477665"}},"outputId":"2e486cb5-50bf-4e3a-9424-0b47593f74cc"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: pathspec 'data/day.gsheet' did not match any files\n"]}]}]}