{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP-551 Assignment 1: Linear Regression on Bike Sharing Data\n",
    "\n",
    "**Group 11**\n",
    "\n",
    "This notebook implements linear regression from scratch and applies it to the UCI Bike Sharing dataset to predict daily bike rental counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install dependencies\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab - uncomment these lines:\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")\n",
    "# PROJECT_PATH = \"/content/drive/MyDrive/comp551-Ass1\"\n",
    "# %cd $PROJECT_PATH\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Set style for better-looking plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Import our custom modules\n",
    "from data_parser import process_csv, ArrayScaler, OutlierHandler\n",
    "from linear_regression import LinearRegression\n",
    "from feature_engineering import add_nonlinear_features\n",
    "\n",
    "print(\"Environment ready!\")\n",
    "print(\"Current directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data Acquisition, Preprocessing, and Exploration\n",
    "\n",
    "## 1.1 Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw dataset\n",
    "raw_df = pd.read_csv(\"data/day.csv\")\n",
    "\n",
    "print(\"Dataset Structure:\")\n",
    "print(f\"Number of samples: {raw_df.shape[0]}\")\n",
    "print(f\"Number of features: {raw_df.shape[1]}\")\n",
    "print(f\"\\nFeature names: {list(raw_df.columns)}\")\n",
    "print(f\"\\nData types:\\n{raw_df.dtypes}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Cleaning and Preprocessing\n",
    "\n",
    "### Missing Values Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_counts = raw_df.isnull().sum()\n",
    "print(f\"Total missing values: {missing_counts.sum()}\")\n",
    "print(f\"\\nMissing values per column:\\n{missing_counts}\")\n",
    "\n",
    "# Check for any non-standard missing value indicators\n",
    "print(f\"\\nDataset info:\")\n",
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding:** The dataset contains no missing values, which is excellent for model training.\n",
    "\n",
    "### Feature Selection and Data Leakage Prevention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features we drop and why:\n",
    "dropped_features = {\n",
    "    \"instant\": \"Row identifier - no predictive value\",\n",
    "    \"dteday\": \"Date string - used only for temporal ordering\",\n",
    "    \"casual\": \"Data leakage - component of target variable (cnt = casual + registered)\",\n",
    "    \"registered\": \"Data leakage - component of target variable\",\n",
    "    \"atemp\": \"High collinearity with 'temp' (r > 0.99)\",\n",
    "    \"workingday\": \"Redundant - can be derived from 'holiday' and 'weekday'\"\n",
    "}\n",
    "\n",
    "print(\"Features dropped and justification:\")\n",
    "for feat, reason in dropped_features.items():\n",
    "    print(f\"  - {feat}: {reason}\")\n",
    "\n",
    "# Verify correlation between temp and atemp\n",
    "print(f\"\\nCorrelation between temp and atemp: {raw_df['temp'].corr(raw_df['atemp']):.4f}\")\n",
    "print(f\"Correlation between casual+registered and cnt: {(raw_df['casual'] + raw_df['registered']).corr(raw_df['cnt']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Feature Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical vs continuous features\n",
    "categorical_features = {\n",
    "    \"season\": \"4 categories (winter, spring, summer, fall) - nominal\",\n",
    "    \"yr\": \"2 categories (2011, 2012) - ordinal\",\n",
    "    \"mnth\": \"12 categories (Jan-Dec) - cyclic ordinal\",\n",
    "    \"holiday\": \"2 categories (yes/no) - binary\",\n",
    "    \"weekday\": \"7 categories (Sun-Sat) - cyclic nominal\",\n",
    "    \"weathersit\": \"4 categories (clear to heavy rain) - ordinal\"\n",
    "}\n",
    "\n",
    "continuous_features = {\n",
    "    \"temp\": \"Normalized temperature in Celsius\",\n",
    "    \"hum\": \"Normalized humidity\",\n",
    "    \"windspeed\": \"Normalized wind speed\"\n",
    "}\n",
    "\n",
    "print(\"Categorical Features:\")\n",
    "for feat, desc in categorical_features.items():\n",
    "    unique_vals = raw_df[feat].nunique()\n",
    "    print(f\"  • {feat} ({unique_vals} unique values): {desc}\")\n",
    "\n",
    "print(\"\\nContinuous Features:\")\n",
    "for feat, desc in continuous_features.items():\n",
    "    print(f\"  • {feat}: {desc}\")\n",
    "    print(f\"    Range: [{raw_df[feat].min():.4f}, {raw_df[feat].max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data Visualization and Exploratory Analysis\n",
    "\n",
    "### Target Variable Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization of target variable\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(raw_df['cnt'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(raw_df['cnt'].mean(), color='red', linestyle='--', label=f\"Mean: {raw_df['cnt'].mean():.0f}\")\n",
    "axes[0].axvline(raw_df['cnt'].median(), color='green', linestyle='--', label=f\"Median: {raw_df['cnt'].median():.0f}\")\n",
    "axes[0].set_xlabel('Total Bike Rentals (cnt)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Target Variable')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(raw_df['cnt'], vert=True)\n",
    "axes[1].set_ylabel('Total Bike Rentals (cnt)')\n",
    "axes[1].set_title('Box Plot of Target Variable')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot for normality\n",
    "stats.probplot(raw_df['cnt'], dist=\"norm\", plot=axes[2])\n",
    "axes[2].set_title('Q-Q Plot (Normality Check)')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('target_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Statistical summary\n",
    "print(\"Target Variable Statistics:\")\n",
    "print(raw_df['cnt'].describe())\n",
    "print(f\"\\nSkewness: {raw_df['cnt'].skew():.4f}\")\n",
    "print(f\"Kurtosis: {raw_df['cnt'].kurtosis():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Features Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions of continuous features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "continuous_cols = ['temp', 'hum', 'windspeed']\n",
    "\n",
    "for idx, col in enumerate(continuous_cols):\n",
    "    # Histogram\n",
    "    axes[0, idx].hist(raw_df[col], bins=40, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    axes[0, idx].axvline(raw_df[col].mean(), color='red', linestyle='--', \n",
    "                         label=f\"Mean: {raw_df[col].mean():.3f}\")\n",
    "    axes[0, idx].set_xlabel(col.capitalize())\n",
    "    axes[0, idx].set_ylabel('Frequency')\n",
    "    axes[0, idx].set_title(f'Distribution of {col.capitalize()}')\n",
    "    axes[0, idx].legend()\n",
    "    axes[0, idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Scatter plot against target\n",
    "    axes[1, idx].scatter(raw_df[col], raw_df['cnt'], alpha=0.5, s=20)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(raw_df[col], raw_df['cnt'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[1, idx].plot(raw_df[col], p(raw_df[col]), \"r--\", alpha=0.8, linewidth=2)\n",
    "    \n",
    "    corr = raw_df[col].corr(raw_df['cnt'])\n",
    "    axes[1, idx].set_xlabel(col.capitalize())\n",
    "    axes[1, idx].set_ylabel('Total Rentals (cnt)')\n",
    "    axes[1, idx].set_title(f'{col.capitalize()} vs Rentals (r={corr:.3f})')\n",
    "    axes[1, idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('continuous_features_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "categorical_cols = ['season', 'yr', 'mnth', 'holiday', 'weekday', 'weathersit']\n",
    "labels_map = {\n",
    "    'season': ['Winter', 'Spring', 'Summer', 'Fall'],\n",
    "    'yr': ['2011', '2012'],\n",
    "    'mnth': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n",
    "    'holiday': ['No', 'Yes'],\n",
    "    'weekday': ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat'],\n",
    "    'weathersit': ['Clear', 'Mist', 'Light Rain', 'Heavy Rain']\n",
    "}\n",
    "\n",
    "for idx, col in enumerate(categorical_cols):\n",
    "    grouped = raw_df.groupby(col)['cnt'].mean().sort_index()\n",
    "    \n",
    "    # Get labels\n",
    "    if col in labels_map:\n",
    "        x_labels = [labels_map[col][int(i)-1 if col != 'weekday' else int(i)] for i in grouped.index]\n",
    "    else:\n",
    "        x_labels = grouped.index\n",
    "    \n",
    "    axes[idx].bar(range(len(grouped)), grouped.values, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "    axes[idx].set_xticks(range(len(grouped)))\n",
    "    axes[idx].set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "    axes[idx].set_xlabel(col.capitalize())\n",
    "    axes[idx].set_ylabel('Average Rentals')\n",
    "    axes[idx].set_title(f'Average Rentals by {col.capitalize()}')\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('categorical_features_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix (excluding dropped features)\n",
    "features_for_corr = [c for c in raw_df.columns if c not in ['instant', 'dteday', 'casual', 'registered', 'atemp', \"workingday\"]]\n",
    "corr_matrix = raw_df[features_for_corr].corr()\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Display correlations with target\n",
    "target_corr = corr_matrix['cnt'].sort_values(ascending=False)\n",
    "print(\"\\nCorrelations with target (cnt):\")\n",
    "print(target_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series visualization\n",
    "raw_df['date'] = pd.to_datetime(raw_df['dteday'])\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# Full time series\n",
    "axes[0].plot(raw_df['date'], raw_df['cnt'], linewidth=1, alpha=0.6)\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Total Rentals')\n",
    "axes[0].set_title('Bike Rentals Over Time (Full Dataset)', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add 30-day rolling average\n",
    "rolling_mean = raw_df['cnt'].rolling(window=30, center=True).mean()\n",
    "axes[0].plot(raw_df['date'], rolling_mean, 'r-', linewidth=2, label='30-day Rolling Avg')\n",
    "axes[0].legend()\n",
    "\n",
    "# Monthly aggregation\n",
    "monthly_avg = raw_df.groupby('mnth')['cnt'].mean().sort_index()\n",
    "month_labels = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "axes[1].bar(range(1, 13), monthly_avg.values, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_xticks(range(1, 13))\n",
    "axes[1].set_xticklabels(month_labels)\n",
    "axes[1].set_xlabel('Month')\n",
    "axes[1].set_ylabel('Average Rentals')\n",
    "axes[1].set_title('Seasonality: Average Rentals by Month', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('temporal_patterns.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers in continuous features using IQR method\n",
    "print(\"Outlier Analysis (IQR Method):\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "for col in continuous_cols:\n",
    "    Q1 = raw_df[col].quantile(0.25)\n",
    "    Q3 = raw_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = raw_df[(raw_df[col] < lower_bound) | (raw_df[col] > upper_bound)]\n",
    "    n_outliers = len(outliers)\n",
    "    pct_outliers = 100 * n_outliers / len(raw_df)\n",
    "    \n",
    "    print(f\"{col.capitalize():12} - Outliers: {n_outliers:3d} ({pct_outliers:5.2f}%)\")\n",
    "    print(f\"{'':12}   Bounds: [{lower_bound:.4f}, {upper_bound:.4f}]\")\n",
    "    \n",
    "print(\"\\nNote: Our preprocessing uses outlier clipping (not removal) to preserve data points.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessed Data Loading\n",
    "\n",
    "Now we load the data using our preprocessing pipeline, which:\n",
    "- Drops irrelevant/leaky features\n",
    "- One-hot encodes categorical variables\n",
    "- Clips outliers to prevent extreme values\n",
    "- Standardizes continuous features (z-score normalization)\n",
    "- Performs time-aware train/test split (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data (baseline: no feature engineering)\n",
    "X_train, X_test, y_train, y_test, feature_index = process_csv(\n",
    "    \"data/day.csv\",\n",
    "    train_frac=0.8,\n",
    "    scaling_method=\"zscore\",\n",
    "    outlier_method=\"quantile\",\n",
    "    one_hot_encode=[\"season\", \"mnth\", \"weekday\"]\n",
    ")\n",
    "\n",
    "print(\"Preprocessed Data Shapes:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test:  {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_test:  {y_test.shape}\")\n",
    "print(f\"\\nTotal features after preprocessing: {X_train.shape[1]}\")\n",
    "print(f\"\\nFeature index mapping:\")\n",
    "for name, idx in sorted(feature_index.items(), key=lambda x: x[1]):\n",
    "    print(f\"  {idx:2d}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Linear Regression (Analytic Solution)\n",
    "\n",
    "## 2.1 Model Implementation\n",
    "\n",
    "Our `LinearRegression` class implements the closed-form solution:\n",
    "\n",
    "$$\\mathbf{w} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$\n",
    "\n",
    "We use `np.linalg.lstsq()` instead of explicit matrix inversion for numerical stability. This function internally uses SVD decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MSE metric\n",
    "def mse(y_true, y_pred):\n",
    "    \"\"\"Calculate Mean Squared Error\"\"\"\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"Calculate Root Mean Squared Error\"\"\"\n",
    "    return np.sqrt(mse(y_true, y_pred))\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    \"\"\"Calculate R-squared score\"\"\"\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    \"\"\"Calculate Mean Absolute Error\"\"\"\n",
    "    return np.mean(np.abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline model (no regularization)\n",
    "baseline_model = LinearRegression()\n",
    "baseline_model.fit(X_train, y_train, lam=0.0)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_baseline = baseline_model.predict(X_train)\n",
    "y_test_pred_baseline = baseline_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "train_mse_baseline = mse(y_train, y_train_pred_baseline)\n",
    "test_mse_baseline = mse(y_test, y_test_pred_baseline)\n",
    "train_rmse_baseline = rmse(y_train, y_train_pred_baseline)\n",
    "test_rmse_baseline = rmse(y_test, y_test_pred_baseline)\n",
    "train_r2_baseline = r2_score(y_train, y_train_pred_baseline)\n",
    "test_r2_baseline = r2_score(y_test, y_test_pred_baseline)\n",
    "\n",
    "\n",
    "print(\"BASELINE MODEL PERFORMANCE (No Feature Engineering)\")\n",
    "print(f\"Training Set:\")\n",
    "print(f\"  MSE:  {train_mse_baseline:,.2f}\")\n",
    "print(f\"  RMSE: {train_rmse_baseline:,.2f}\")\n",
    "print(f\"  R²:   {train_r2_baseline:.4f}\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  MSE:  {test_mse_baseline:,.2f}\")\n",
    "print(f\"  RMSE: {test_rmse_baseline:,.2f}\")\n",
    "print(f\"  R²:   {test_r2_baseline:.4f}\")\n",
    "print(f\"\\nGeneralization Gap (Test - Train RMSE): {test_rmse_baseline - train_rmse_baseline:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Visualize Baseline Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Training set predictions\n",
    "axes[0].scatter(y_train, y_train_pred_baseline, alpha=0.5, s=30)\n",
    "axes[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], \n",
    "             'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual Rentals', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted Rentals', fontsize=12)\n",
    "axes[0].set_title(f'Training Set Predictions (R² = {train_r2_baseline:.4f})', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test set predictions\n",
    "axes[1].scatter(y_test, y_test_pred_baseline, alpha=0.5, s=30, color='orange')\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "             'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[1].set_xlabel('Actual Rentals', fontsize=12)\n",
    "axes[1].set_ylabel('Predicted Rentals', fontsize=12)\n",
    "axes[1].set_title(f'Test Set Predictions (R² = {test_r2_baseline:.4f})', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('baseline_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "train_residuals = y_train - y_train_pred_baseline\n",
    "test_residuals = y_test - y_test_pred_baseline\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Residual plot - Training\n",
    "axes[0, 0].scatter(y_train_pred_baseline, train_residuals, alpha=0.5, s=30)\n",
    "axes[0, 0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Predicted Values', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Residuals', fontsize=11)\n",
    "axes[0, 0].set_title('Training Set: Residual Plot', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual plot - Test\n",
    "axes[0, 1].scatter(y_test_pred_baseline, test_residuals, alpha=0.5, s=30, color='orange')\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Predicted Values', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Residuals', fontsize=11)\n",
    "axes[0, 1].set_title('Test Set: Residual Plot', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual distribution - Training\n",
    "axes[1, 0].hist(train_residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].axvline(train_residuals.mean(), color='r', linestyle='--', \n",
    "                   label=f'Mean: {train_residuals.mean():.2f}')\n",
    "axes[1, 0].set_xlabel('Residuals', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[1, 0].set_title('Training Set: Residual Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual distribution - Test\n",
    "axes[1, 1].hist(test_residuals, bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1, 1].axvline(test_residuals.mean(), color='r', linestyle='--', \n",
    "                   label=f'Mean: {test_residuals.mean():.2f}')\n",
    "axes[1, 1].set_xlabel('Residuals', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Frequency', fontsize=11)\n",
    "axes[1, 1].set_title('Test Set: Residual Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('baseline_residuals.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Residual Statistics:\")\n",
    "print(f\"Training - Mean: {train_residuals.mean():.2f}, Std: {train_residuals.std():.2f}\")\n",
    "print(f\"Test     - Mean: {test_residuals.mean():.2f}, Std: {test_residuals.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Non-linear Feature Engineering\n",
    "\n",
    "We explore three types of feature engineering:\n",
    "1. **Polynomial features**: temp², hum², windspeed²\n",
    "2. **Interaction features**: temp×hum, temp×windspeed, temp×weathersit\n",
    "3. **Trigonometric encoding**: sin/cos of month (captures cyclical nature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data without one-hot encoding month (needed for sin/cos transform)\n",
    "X_train_fe, X_test_fe, y_train_fe, y_test_fe, fi_fe = process_csv(\n",
    "    \"data/day.csv\",\n",
    "    train_frac=0.8,\n",
    "    scaling_method=\"zscore\",\n",
    "    outlier_method=\"quantile\",\n",
    "    one_hot_encode=[\"season\", \"weekday\"]  # Don't one-hot encode month\n",
    ")\n",
    "\n",
    "# Add all three types of engineered features\n",
    "X_train_fe, fi_fe = add_nonlinear_features(\n",
    "    X_train_fe, fi_fe,\n",
    "    polynomial=True,\n",
    "    interaction=True,\n",
    "    transform=True  # sin/cos of month\n",
    ")\n",
    "\n",
    "X_test_fe, _ = add_nonlinear_features(\n",
    "    X_test_fe, fi_fe,\n",
    "    polynomial=True,\n",
    "    interaction=True,\n",
    "    transform=True\n",
    ")\n",
    "\n",
    "print(\"Feature Engineering Applied:\")\n",
    "print(f\"Original features: {X_train.shape[1] - 11} + 11 one-hot encoded \\\"mnth\\\" variables\")\n",
    "print(f\"Engineered features: {X_train_fe.shape[1] - 1} + 1 original \\\"mnth\\\" variable\")\n",
    "print(f\"New features added: {(X_train_fe.shape[1] - 1) - (X_train.shape[1] - 11)}\")\n",
    "print(f\"\\nNew feature names:\")\n",
    "new_features = ['temp_sq', 'hum_sq', 'windspeed_sq', 'temp_hum', 'temp_windspeed', \n",
    "                'temp_weathersit', 'month_sin', 'month_cos']\n",
    "for feat in new_features:\n",
    "    if feat in fi_fe:\n",
    "        print(f\"  • {feat} (index {fi_fe[feat]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Train Feature-Engineered Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to re-scale the engineered features\n",
    "continuous_idx_fe = [fi_fe[name] for name in ['temp', 'hum', 'windspeed', \n",
    "                                                'temp_sq', 'hum_sq', 'windspeed_sq',\n",
    "                                                'temp_hum', 'temp_windspeed', 'temp_weathersit']]\n",
    "\n",
    "scaler_fe = ArrayScaler(method=\"zscore\", idx=continuous_idx_fe)\n",
    "scaler_fe.fit(X_train_fe)\n",
    "X_train_fe = scaler_fe.transform(X_train_fe)\n",
    "X_test_fe = scaler_fe.transform(X_test_fe)\n",
    "\n",
    "# Train model with engineered features\n",
    "model_fe = LinearRegression()\n",
    "model_fe.fit(X_train_fe, y_train_fe, lam=0.0)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_fe = model_fe.predict(X_train_fe)\n",
    "y_test_pred_fe = model_fe.predict(X_test_fe)\n",
    "\n",
    "# Metrics\n",
    "train_mse_fe = mse(y_train_fe, y_train_pred_fe)\n",
    "test_mse_fe = mse(y_test_fe, y_test_pred_fe)\n",
    "train_rmse_fe = rmse(y_train_fe, y_train_pred_fe)\n",
    "test_rmse_fe = rmse(y_test_fe, y_test_pred_fe)\n",
    "train_r2_fe = r2_score(y_train_fe, y_train_pred_fe)\n",
    "test_r2_fe = r2_score(y_test_fe, y_test_pred_fe)\n",
    "\n",
    "print(\"FEATURE-ENGINEERED MODEL PERFORMANCE\")\n",
    "print(f\"Training Set:\")\n",
    "print(f\"  MSE:  {train_mse_fe:,.2f}\")\n",
    "print(f\"  RMSE: {train_rmse_fe:,.2f}\")\n",
    "print(f\"  R²:   {train_r2_fe:.4f}\")\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  MSE:  {test_mse_fe:,.2f}\")\n",
    "print(f\"  RMSE: {test_rmse_fe:,.2f}\")\n",
    "print(f\"  R²:   {test_r2_fe:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Compare Baseline vs Feature-Engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Train MSE', 'Test MSE', 'Train RMSE', 'Test RMSE', 'Train R²', 'Test R²'],\n",
    "    'Baseline': [\n",
    "        f\"{train_mse_baseline:,.2f}\",\n",
    "        f\"{test_mse_baseline:,.2f}\",\n",
    "        f\"{train_rmse_baseline:,.2f}\",\n",
    "        f\"{test_rmse_baseline:,.2f}\",\n",
    "        f\"{train_r2_baseline:.4f}\",\n",
    "        f\"{test_r2_baseline:.4f}\"\n",
    "    ],\n",
    "    'Feature Engineered': [\n",
    "        f\"{train_mse_fe:,.2f}\",\n",
    "        f\"{test_mse_fe:,.2f}\",\n",
    "        f\"{train_rmse_fe:,.2f}\",\n",
    "        f\"{test_rmse_fe:,.2f}\",\n",
    "        f\"{train_r2_fe:.4f}\",\n",
    "        f\"{test_r2_fe:.4f}\"\n",
    "    ],\n",
    "    'Improvement': [\n",
    "        f\"{100*(train_mse_baseline - train_mse_fe)/train_mse_baseline:.2f}%\",\n",
    "        f\"{100*(test_mse_baseline - test_mse_fe)/test_mse_baseline:.2f}%\",\n",
    "        f\"{100*(train_rmse_baseline - train_rmse_fe)/train_rmse_baseline:.2f}%\",\n",
    "        f\"{100*(test_rmse_baseline - test_rmse_fe)/test_rmse_baseline:.2f}%\",\n",
    "        f\"{100*(train_r2_fe - train_r2_baseline)/train_r2_baseline:.2f}%\",\n",
    "        f\"{100*(test_r2_fe - test_r2_baseline)/test_r2_baseline:.2f}%\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"MODEL COMPARISON: Baseline vs Feature-Engineered\")\n",
    "print(comparison_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of improvement\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# RMSE comparison\n",
    "metrics = ['Train RMSE', 'Test RMSE']\n",
    "baseline_scores = [train_rmse_baseline, test_rmse_baseline]\n",
    "fe_scores = [train_rmse_fe, test_rmse_fe]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, baseline_scores, width, label='Baseline', alpha=0.8)\n",
    "axes[0].bar(x + width/2, fe_scores, width, label='Feature Engineered', alpha=0.8)\n",
    "axes[0].set_ylabel('RMSE', fontsize=12)\n",
    "axes[0].set_title('RMSE Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(metrics)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# R² comparison\n",
    "r2_metrics = ['Train R²', 'Test R²']\n",
    "baseline_r2 = [train_r2_baseline, test_r2_baseline]\n",
    "fe_r2 = [train_r2_fe, test_r2_fe]\n",
    "\n",
    "axes[1].bar(x - width/2, baseline_r2, width, label='Baseline', alpha=0.8)\n",
    "axes[1].bar(x + width/2, fe_r2, width, label='Feature Engineered', alpha=0.8)\n",
    "axes[1].set_ylabel('R² Score', fontsize=12)\n",
    "axes[1].set_title('R² Score Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(r2_metrics)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "axes[1].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Analysis and Discussion\n",
    "\n",
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and analyze feature weights from baseline model\n",
    "feature_names = list(feature_index.keys())\n",
    "weights_baseline = baseline_model.w[1:]  # Exclude bias term\n",
    "\n",
    "# Create DataFrame for easier analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Weight': weights_baseline,\n",
    "    'Abs_Weight': np.abs(weights_baseline)\n",
    "}).sort_values('Abs_Weight', ascending=False)\n",
    "\n",
    "print(\"Top 15 Most Important Features (by absolute weight):\")\n",
    "print(feature_importance.head(15).to_string(index=False))\n",
    "\n",
    "# Visualize top features\n",
    "top_n = 15\n",
    "top_features = feature_importance.head(top_n)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['green' if w > 0 else 'red' for w in top_features['Weight']]\n",
    "plt.barh(range(top_n), top_features['Weight'], color=colors, alpha=0.7, edgecolor='black')\n",
    "plt.yticks(range(top_n), top_features['Feature'])\n",
    "plt.xlabel('Weight Coefficient', fontsize=12)\n",
    "plt.title('Top 15 Feature Weights (Green=Positive, Red=Negative)', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different regularization strengths\n",
    "lambdas = [0.0, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "ridge_results = []\n",
    "\n",
    "for lam in lambdas:\n",
    "    model_ridge = LinearRegression()\n",
    "    model_ridge.fit(X_train, y_train, lam=lam)\n",
    "    \n",
    "    y_train_pred_ridge = model_ridge.predict(X_train)\n",
    "    y_test_pred_ridge = model_ridge.predict(X_test)\n",
    "    \n",
    "    ridge_results.append({\n",
    "        'lambda': lam,\n",
    "        'train_rmse': rmse(y_train, y_train_pred_ridge),\n",
    "        'test_rmse': rmse(y_test, y_test_pred_ridge),\n",
    "        'train_r2': r2_score(y_train, y_train_pred_ridge),\n",
    "        'test_r2': r2_score(y_test, y_test_pred_ridge)\n",
    "    })\n",
    "\n",
    "ridge_df = pd.DataFrame(ridge_results)\n",
    "print(\"\\nRidge Regression Results (varying λ):\")\n",
    "print(ridge_df.to_string(index=False))\n",
    "\n",
    "# Plot regularization path\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "axes[0].plot(ridge_df['lambda'], ridge_df['train_rmse'], 'o-', label='Train RMSE', linewidth=2)\n",
    "axes[0].plot(ridge_df['lambda'], ridge_df['test_rmse'], 's-', label='Test RMSE', linewidth=2)\n",
    "axes[0].set_xlabel('Regularization Strength (λ)', fontsize=12)\n",
    "axes[0].set_ylabel('RMSE', fontsize=12)\n",
    "axes[0].set_title('Effect of Regularization on RMSE', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(ridge_df['lambda'], ridge_df['train_r2'], 'o-', label='Train R²', linewidth=2)\n",
    "axes[1].plot(ridge_df['lambda'], ridge_df['test_r2'], 's-', label='Test R²', linewidth=2)\n",
    "axes[1].set_xlabel('Regularization Strength (λ)', fontsize=12)\n",
    "axes[1].set_ylabel('R² Score', fontsize=12)\n",
    "axes[1].set_title('Effect of Regularization on R²', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('regularization_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate learning curves to analyze bias-variance tradeoff\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "n_train = len(X_train)\n",
    "\n",
    "train_scores_baseline = []\n",
    "test_scores_baseline = []\n",
    "train_scores_fe = []\n",
    "test_scores_fe = []\n",
    "\n",
    "for train_size in train_sizes:\n",
    "    n_samples = int(train_size * n_train)\n",
    "    \n",
    "    # Baseline model\n",
    "    model_temp = LinearRegression()\n",
    "    model_temp.fit(X_train[:n_samples], y_train[:n_samples])\n",
    "    train_scores_baseline.append(rmse(y_train[:n_samples], model_temp.predict(X_train[:n_samples])))\n",
    "    test_scores_baseline.append(rmse(y_test, model_temp.predict(X_test)))\n",
    "    \n",
    "    # Feature-engineered model\n",
    "    model_temp_fe = LinearRegression()\n",
    "    model_temp_fe.fit(X_train_fe[:n_samples], y_train_fe[:n_samples])\n",
    "    train_scores_fe.append(rmse(y_train_fe[:n_samples], model_temp_fe.predict(X_train_fe[:n_samples])))\n",
    "    test_scores_fe.append(rmse(y_test_fe, model_temp_fe.predict(X_test_fe)))\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_sizes * n_train, train_scores_baseline, 'o-', label='Baseline Train', linewidth=2)\n",
    "plt.plot(train_sizes * n_train, test_scores_baseline, 's-', label='Baseline Test', linewidth=2)\n",
    "plt.plot(train_sizes * n_train, train_scores_fe, '^-', label='FE Train', linewidth=2)\n",
    "plt.plot(train_sizes * n_train, test_scores_fe, 'v-', label='FE Test', linewidth=2)\n",
    "plt.xlabel('Training Set Size', fontsize=12)\n",
    "plt.ylabel('RMSE', fontsize=12)\n",
    "plt.title('Learning Curves: Effect of Training Data Size', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('learning_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics and Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FINAL PROJECT SUMMARY\")\n",
    "\n",
    "print(\"\\n1. DATASET CHARACTERISTICS:\")\n",
    "print(f\"   - Total samples: {len(raw_df)}\")\n",
    "print(f\"   - Training samples: {len(y_train)}\")\n",
    "print(f\"   - Test samples: {len(y_test)}\")\n",
    "print(f\"   - Original features: {len(feature_index)}\")\n",
    "print(f\"   - Engineered features: {X_train_fe.shape[1]}\")\n",
    "\n",
    "print(\"\\n2. PREPROCESSING DECISIONS:\")\n",
    "print(\"   - Missing values: None found - no imputation needed\")\n",
    "print(\"   - Dropped features: instant, dteday, casual, registered, atemp, workingday\")\n",
    "print(\"   - Categorical encoding: One-hot encoding for season, month, weekday\")\n",
    "print(\"   - Scaling method: Z-score standardization (mean=0, std=1)\")\n",
    "print(\"   - Outlier handling: Quantile clipping (1%-99%)\")\n",
    "print(\"   - Train/test split: 80/20 time-aware split\")\n",
    "\n",
    "print(\"\\n3. BASELINE MODEL RESULTS:\")\n",
    "print(f\"   - Training RMSE: {train_rmse_baseline:,.2f}\")\n",
    "print(f\"   - Test RMSE: {test_rmse_baseline:,.2f}\")\n",
    "print(f\"   - Training R²: {train_r2_baseline:.4f}\")\n",
    "print(f\"   - Test R²: {test_r2_baseline:.4f}\")\n",
    "\n",
    "print(\"\\n4. FEATURE ENGINEERING RESULTS:\")\n",
    "print(\"   - Added 8 new features: polynomial, interaction, and trigonometric\")\n",
    "print(f\"   - Training RMSE: {train_rmse_fe:,.2f} ({100*(train_rmse_baseline-train_rmse_fe)/train_rmse_baseline:.1f}% improvement)\")\n",
    "print(f\"   - Test RMSE: {test_rmse_fe:,.2f} ({100*(test_rmse_baseline-test_rmse_fe)/test_rmse_baseline:.1f}% improvement)\")\n",
    "print(f\"   - Training R²: {train_r2_fe:.4f}\")\n",
    "print(f\"   - Test R²: {test_r2_fe:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\n5. KEY FINDINGS:\")\n",
    "print(\"   - Temperature is the most predictive feature\")\n",
    "print(\"   - Clear seasonality patterns: summer/fall > winter/spring\")\n",
    "print(\"   - Feature engineering reduced training error significantly\")\n",
    "print(\"   - Model shows good generalization (reasonable train-test gap)\")\n",
    "print(\"   - Ridge regularization offers minimal benefit (dataset is not overfit)\")\n",
    "\n",
    "print(\"\\n6. LIMITATIONS:\")\n",
    "print(\"   - Linear model cannot capture complex non-linear relationships\")\n",
    "print(\"   - Assumes independence between observations (ignores temporal autocorrelation)\")\n",
    "print(\"   - Test set is from a specific time period - may not generalize to future years\")\n",
    "print(\"   - Weather features are normalized - harder to interpret coefficients\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results for Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results to CSV for easy table generation in LaTeX\n",
    "results_summary = pd.DataFrame({\n",
    "    'Model': ['Baseline', 'Feature Engineered'],\n",
    "    'Train_MSE': [train_mse_baseline, train_mse_fe],\n",
    "    'Test_MSE': [test_mse_baseline, test_mse_fe],\n",
    "    'Train_RMSE': [train_rmse_baseline, train_rmse_fe],\n",
    "    'Test_RMSE': [test_rmse_baseline, test_rmse_fe],\n",
    "    'Train_R2': [train_r2_baseline, train_r2_fe],\n",
    "    'Test_R2': [test_r2_baseline, test_r2_fe],\n",
    "    'Num_Features': [X_train.shape[1], X_train_fe.shape[1]]\n",
    "})\n",
    "\n",
    "results_summary.to_csv('model_results.csv', index=False)\n",
    "feature_importance.to_csv('feature_importance.csv', index=False)\n",
    "ridge_df.to_csv('regularization_results.csv', index=False)\n",
    "\n",
    "print(\"Results exported to CSV files for report generation!\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"  - model_results.csv\")\n",
    "print(\"  - feature_importance.csv\")\n",
    "print(\"  - regularization_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
